{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.03: Classifying Credit Approval\n",
    "\n",
    "In this exercise, we will be using the German credit approval dataset, and train a neural network to classify whether an individual is creditworthy or not.\n",
    "\n",
    "The following steps will help you complete the exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Import the `loadtxt` method from `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Create a variable called `file_url` containing the link to the raw dataset. Use `data/german_scaled.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = 'https://raw.githubusercontent.com/applied-data-mining-master/syllabus_intelligencesystems/main/data/german_scaled.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Load the data into a variable called `data` using `loadtxt()` and specify the `delimiter=','` parameter. Print its content:\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "array([[0.        , 0.33333333, 0.02941176, ..., 0.      , 1.      ,\n",
    "        1.        ],\n",
    "       [1.        , 0.        , 0.64705882, ..., 0.      , 0.      ,\n",
    "        1.        ],\n",
    "       [0.        , 1.        , 0.11764706, ..., 1.      , 0.      ,\n",
    "        1.        ],\n",
    "       ...,\n",
    "       [0.        , 1.        , 0.11764706, ..., 0.      , 0.      ,\n",
    "        1.        ],\n",
    "       [1.        , 0.33333333, 0.60294118, ..., 0.      , 1.      ,\n",
    "        1.        ],\n",
    "       [0.        , 0.        , 0.60294118, ..., 0.      , 0.      ,\n",
    "        1.        ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.33333333, 0.02941176, ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.        , 0.64705882, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 1.        , 0.11764706, ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.        , 1.        , 0.11764706, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.33333333, 0.60294118, ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.60294118, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadtxt(file_url, delimiter=',')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Create a variable called `label` that contains the data only from the first column (this will be our response variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Create a variable called `features` that contains all the data except for the first column (which corresponds to the response variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Import the `train_test_split` method from `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- Split the data into training and testing sets and save the results into four variables called `features_train`, `features_test`, `label_train`, and `label_test`. Use $20\\%$ of the data for testing and specify `random_state=7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, label_train, label_test = train_test_split(features, label, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.- Import `numpy` as np, `tensorflow` as tf, and `layers` from `tensorflow.keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.- Set 1 as the seed for `numpy` and `tensorflow` using `np.random_seed()` and `tf.random.set_seed()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.- Instantantiate a `tf.keras.Sequential()` class and save it into a variable called `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.- Instantantiate a `layers.Dense()` class with 16 neurons, `activation='relu'`, and `input_shape=[19]`, then save it into a variable called `layer1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = layers.Dense(16, activation='relu', input_shape=[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.- Instantantiate a second `layers.Dense()` class with 1 neuron and `activation='sigmoid'`, then save it into a variable called `final_layer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer = layers.Dense(1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.- Add the two layers you just defined to the model using `.add()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layer1)\n",
    "model.add(final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.- Instantantiate a `tf.keras.optimizers.Adam()` class with 0.001 as the learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.- Compile the neural network using `.compile()` with `loss='binary_crossentropy'`, `optimizer=optimizer, metrics=['accuracy']` as shown in the following code snippet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.- Print a summary of the model using `.summary()`\n",
    "\n",
    "Output:\n",
    "\n",
    "![Figure 6.13](img/fig6_13.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 337\n",
      "Trainable params: 337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output summarizes the architecture of our neural networks. We can see it is composed of three layers, as expected, and we know each layer's output size and number of parameters, which corresponds to the weights and biases. For instance, the first layer has 16 neurons and 320 parameters to be learned (weights and biases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.- Next, fit the neural networks with the training set and specify `epochs=10`\n",
    "\n",
    "Output:\n",
    "\n",
    "![Figure 6.14](img/fig6_14.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 1ms/step - loss: 0.7590 - accuracy: 0.3596\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5301\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6879\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.6869\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.6938\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.6819\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7040\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.6626\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.6859\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4d14114730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, label_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output provides a lot of information about the training of the neural network. The first line tells us the training set was composed of 800 observations. Then we can see the results of each epoch:\n",
    "\n",
    "Total processing time in seconds\n",
    "\n",
    "Processing time by data sample in us/sample\n",
    "\n",
    "Loss value and accuracy score\n",
    "\n",
    "The final result of this neural network is the last epoch (epoch=10), where we achieved an accuracy score of 0.6888. But we can see that the trend was improving: the accuracy score was still increasing after each epoch. So, we may get better results if we train the neural network for longer by increasing the number of epochs or lowering the learning rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
